{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.111148Z",
     "start_time": "2024-12-16T11:46:15.066354Z"
    }
   },
   "source": [
    "# Load data\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy.constants import yocto\n",
    "\n",
    "data = pd.read_csv('data/Movie_Overview_Classification.csv',\n",
    "                   encoding='utf-8', \n",
    "                   delimiter=',',\n",
    "                   quotechar='|',\n",
    "                   quoting=csv.QUOTE_MINIMAL)\n",
    "X = data['overview']\n",
    "y = data['genre_Drama']\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id                                           overview  genre_Drama\n",
       "0   1  When Lou, who has become the \"father of the In...            0\n",
       "1   2  Mia Thermopolis is now a college graduate and ...            1\n",
       "2   3  Under the direction of a ruthless instructor, ...            1\n",
       "3   4  Vidya Bagchi (Vidya Balan) arrives in Kolkata ...            1\n",
       "4   5  Marine Boy is the story of a former national s...            0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>genre_Drama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.207939Z",
     "start_time": "2024-12-16T11:46:15.191157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform pre-processing, e.g., replacing missing values if existing\n",
    "data = data.fillna('')\n",
    "data.head()"
   ],
   "id": "95652db3bb28c12a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id                                           overview  genre_Drama\n",
       "0   1  When Lou, who has become the \"father of the In...            0\n",
       "1   2  Mia Thermopolis is now a college graduate and ...            1\n",
       "2   3  Under the direction of a ruthless instructor, ...            1\n",
       "3   4  Vidya Bagchi (Vidya Balan) arrives in Kolkata ...            1\n",
       "4   5  Marine Boy is the story of a former national s...            0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>genre_Drama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Implement a classifier",
   "id": "b8ddf1292a96be7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.596054Z",
     "start_time": "2024-12-16T11:46:15.321302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize text with CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X)\n",
    "X_train_counts.shape"
   ],
   "id": "274d2daabff93793",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CountVectorizer\n\u001B[0;32m      3\u001B[0m count_vect \u001B[38;5;241m=\u001B[39m CountVectorizer()\n\u001B[1;32m----> 4\u001B[0m X_train_counts \u001B[38;5;241m=\u001B[39m \u001B[43mcount_vect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m X_train_counts\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001B[0m, in \u001B[0;36mCountVectorizer.fit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1364\u001B[0m             warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1365\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUpper case characters found in\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1366\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m vocabulary while \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlowercase\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1367\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is True. These entries will not\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1368\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be matched with any documents\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1369\u001B[0m             )\n\u001B[0;32m   1370\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1372\u001B[0m vocabulary, X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_count_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfixed_vocabulary_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbinary:\n\u001B[0;32m   1375\u001B[0m     X\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfill(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1259\u001B[0m, in \u001B[0;36mCountVectorizer._count_vocab\u001B[1;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[0;32m   1257\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m raw_documents:\n\u001B[0;32m   1258\u001B[0m     feature_counter \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m-> 1259\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m \u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1260\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1261\u001B[0m             feature_idx \u001B[38;5;241m=\u001B[39m vocabulary[feature]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:103\u001B[0m, in \u001B[0;36m_analyze\u001B[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001B[39;00m\n\u001B[0;32m     83\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001B[39;00m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decoder \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 103\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m analyzer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    105\u001B[0m     doc \u001B[38;5;241m=\u001B[39m analyzer(doc)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:236\u001B[0m, in \u001B[0;36m_VectorizerMixin.decode\u001B[1;34m(self, doc)\u001B[0m\n\u001B[0;32m    233\u001B[0m     doc \u001B[38;5;241m=\u001B[39m doc\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecode_error)\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m doc \u001B[38;5;129;01mis\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan:\n\u001B[1;32m--> 236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    238\u001B[0m     )\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m doc\n",
      "\u001B[1;31mValueError\u001B[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.713404300Z",
     "start_time": "2024-12-16T11:39:11.404599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transform the count matrix to a normalized term-frequency or term-frequency times inverse document-frequency representation \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ],
   "id": "2d906ab99e7b0810",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 17436)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.713404300Z",
     "start_time": "2024-12-16T11:39:29.222198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tf, y)\n",
    "\n"
   ],
   "id": "c16fb4a6fd5a308a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.713404300Z",
     "start_time": "2024-12-16T11:39:36.540775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ],
   "id": "2da2f26800f3cc79",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.713404300Z",
     "start_time": "2024-12-16T11:39:43.703236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the classifier\n",
    "text_clf = text_clf.fit(X, y)"
   ],
   "id": "c1426cbe916f0853",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:46:15.713404300Z",
     "start_time": "2024-12-16T11:39:52.572966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Measure accuracy using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(text_clf, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ],
   "id": "389c18b5fe0fad2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66 (+/- 0.02)\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
